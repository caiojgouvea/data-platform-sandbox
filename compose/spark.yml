networks:
  datalab-net:
    external: true

services:
  spark-master:
    image: bitnami/spark:3.5
    container_name: datalab-spark-master
    user: "1001:0"
    ports:
      - "18081:8080"
    environment:
      SPARK_MODE: master
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
      SPARK_MASTER_HOST: spark-master
      SPARK_DAEMON_MEMORY: 512m

      # identidades simples (evita Kerberos)
      SPARK_USER: "1001"
      HADOOP_USER_NAME: "1001"
      USER: "1001"
      LOGNAME: "1001"

      # garantir confs e JVM
      SPARK_CONF_DIR: /opt/bitnami/spark/conf
      HADOOP_CONF_DIR: /opt/bitnami/spark/conf
      HOME: /opt/bitnami/spark
      JAVA_TOOL_OPTIONS: "-Duser.home=/opt/bitnami/spark -Duser.name=spark -Dhadoop.security.authentication=simple -Djava.security.krb5.realm= -Djava.security.krb5.kdc="
      SPARK_SUBMIT_OPTS: "-Duser.home=/opt/bitnami/spark -Duser.name=spark -Dhadoop.security.authentication=simple -Djava.security.krb5.realm= -Djava.security.krb5.kdc="

      # segurança off para lab
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"

      # credenciais para S3A (via chain padrão)
      AWS_ACCESS_KEY_ID: "${MINIO_ROOT_USER}"
      AWS_SECRET_ACCESS_KEY: "${MINIO_ROOT_PASSWORD}"
    env_file:
      - ../.env
    volumes:
      - ./create-user.sh:/docker-entrypoint-initdb.d/create-user.sh
      - ../spark/conf:/opt/bitnami/spark/conf
    tmpfs:
      - /tmp/ivy2:size=1g,mode=1777
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 5s
      timeout: 2s
      retries: 30
    networks:
      - datalab-net
    # limites (opcional)
    cpus: "0.5"
    mem_limit: "1g"
    ulimits:
      nofile:
        soft: 65536
        hard: 65536

  spark-worker:
    image: bitnami/spark:3.5
    user: "1001:0"
    container_name: datalab-spark-worker-1
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "18082:8081"
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_CORES: 3
      SPARK_WORKER_MEMORY: 8G
      SPARK_DAEMON_MEMORY: 1g

      SPARK_USER: "1001"
      HADOOP_USER_NAME: "1001"
      USER: "1001"
      LOGNAME: "1001"

      SPARK_CONF_DIR: /opt/bitnami/spark/conf
      HADOOP_CONF_DIR: /opt/bitnami/spark/conf
      HOME: /opt/bitnami/spark
      JAVA_TOOL_OPTIONS: "-Duser.home=/opt/bitnami/spark -Duser.name=spark -Dhadoop.security.authentication=simple -Djava.security.krb5.realm= -Djava.security.krb5.kdc="
      SPARK_SUBMIT_OPTS: "-Duser.home=/opt/bitnami/spark -Duser.name=spark -Dhadoop.security.authentication=simple -Djava.security.krb5.realm= -Djava.security.krb5.kdc="

      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"

      AWS_ACCESS_KEY_ID: "${MINIO_ROOT_USER}"
      AWS_SECRET_ACCESS_KEY: "${MINIO_ROOT_PASSWORD}"
    env_file:
      - ../.env
    volumes:
      - ../spark/conf:/opt/bitnami/spark/conf
      - ./create-user.sh:/docker-entrypoint-initdb.d/create-user.sh
    tmpfs:
      - /tmp/ivy2:size=1g,mode=1777
    networks:
      - datalab-net
    # limites (opcional)
    cpus: "3.0"
    mem_limit: "8g"
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
